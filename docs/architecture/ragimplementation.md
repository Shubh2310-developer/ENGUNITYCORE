# Engunity AI: SOTA RAG Implementation Guide

This document details the actual technical implementation of the **ChatGPT-level** RAG system in Engunity. It follows the principles of high precision, low latency, and infinite context management.

---

## üèóÔ∏è 1. High-Level Architecture (The "Brain")

The system is no longer a simple search-and-generate loop. It is an **Adaptive Multi-Stage Pipeline**:

1.  **Intent Classification**: Routes queries to `SIMPLE` (Direct Gen), `SINGLE_HOP` (Vector RAG), or `MULTI_HOP` (GraphRAG) logic.
2.  **Query Expansion**: Generates **Multi-Query** variations and **Step-back** abstractions.
3.  **Hybrid Retrieval**: Fuses **BGE-Large** vectors with **BM25** keyword ranks using **RRF**.
4.  **Context Refinement**: Applies **Contextual Compression** (LLM-based) to strip noise.
5.  **Grounded Synthesis**: Generates answers using citations and **Hierarchical Memory** for long-term awareness.

---

## üì• 2. Document Ingestion (Backend)

### 2.1 SOTA Text Extraction
- **PDF/DOCX**: High-fidelity extraction with **EasyOCR fallback** for scanned content.
- **Image Processing**: Synchronous validation + Asynchronous **YOLOv8** object detection and spatial mapping.

### 2.2 Semantic Chunking
We have moved away from fixed character splitting. Chunks are now created using **AI-driven semantic boundaries** which preserve the logical flow of ideas.

### 2.3 Production Indexing (HNSW)
The system utilizes **FAISS HNSW (IndexHNSWFlat)**.
- **Time Complexity**: O(log n) search.
- **Accuracy**: 99%+ recall on 1024-dimensional `bge-large` vectors.

---

## üí¨ 3. Chat & Personalization

### 3.1 Hierarchical Memory
To handle the "Context Window" problem, Engunity implements a recursive memory system:
- **Active Context**: The most recent 8 messages are passed as-is.
- **Compressed Memory**: Older history (up to 50 messages) is summarized into a concise "Memory Block" by a fast inference model.
- **Benefit**: The AI "remembers" your preferences and past data without overflowing the token limit.

### 3.2 Multi-Modal Fusion
Vision is integrated directly into the RAG flow. When an image is referenced:
1.  **YOLOv8** identifies object layout.
2.  **Gemini** describes the scene.
3.  **EasyOCR** reads the text.
4.  **Result**: The LLM gets a structured "Visual Information" block including spatial regions (e.g., "laptop in the center").

---

## üé® 4. Premium Interface

The frontend is built for **Transparency and Speed**:
- **Metadata Badges**: Real-time visibility into strategy, memory usage, and compression.
- **Glassmorphism Theme**: High-end dark mode aesthetics.
- **SSE Streaming**: Sub-200ms time-to-first-token.

---

## üõ†Ô∏è Technical Stack Summary

| Layer | Component |
| :--- | :--- |
| **Embeddings** | `BAAI/bge-large-en-v1.5` |
| **Search** | FAISS HNSW + BM25Okapi |
| **Vision** | YOLOv8-nano + Gemini 2.0 Flash |
| **LLM** | Groq Llama 3.3 70B (Primary) |
| **Environment**| Conda `engunity` (RTX 4050 Optimized) |

---

*Last Updated: 2026-01-17*
*Status: Fully Deployed*
